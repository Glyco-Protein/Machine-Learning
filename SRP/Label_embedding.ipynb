{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41b6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig,BertTokenizer,BertModel,BertForMultipleChoice\n",
    "from torch import nn\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "excel_file = 'D:/基于深度学习的海量文本处理/第1阶段/10w.xlsx'\n",
    "data_frame = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词预处理\n",
    "stop_words = ['您好','你好','很高兴为您服务','请问有什么可以帮您','client','user',':',' ']\n",
    "def ProcessStopWords(text):\n",
    "    for word in stop_words:\n",
    "        text = text.replace(word,'')\n",
    "    return text\n",
    "\n",
    "data_frame['转写文本'] = data_frame['转写文本'].map(ProcessStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签预处理\n",
    "def ProcessLabels(text):\n",
    "    word = '>>'\n",
    "    text = text.replace(word,'>')\n",
    "    return text\n",
    "\n",
    "data_frame['服务请求'] = data_frame['服务请求'].map(ProcessLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa56f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    哎我想问一下,我这个一三九的号码那个扣费方式是怎么样的扣费方式的话它是每个月呢就是每个月的一...\n",
       "1    喂我那个宽带不能用宽带故障了是吗哦现在不能用前前几天就不能用了稍等我帮您看一下嗯稍等一下3天...\n",
       "2    哎我我办理这个那个我想问一下我这个号码有没有开通5g套餐呀我看一下您这里有开通5g业务可以享...\n",
       "3    请不要挂机您拨叫的用户正在通话中请唔好挂机您拨叫凯用户正在通话中嗯由于您多次没有声音我将结束...\n",
       "4    喂我想咨询一下我的那个联通卡怎么回事啊,我都没用过嗯您可以提供一下吗这个号码就是我我号码我都...\n",
       "5    嗯我想问一下我这个卡是啊升了5g上次是帮我升了5g然后现在是月租是54.5元上网费又是30一...\n",
       "6                                                不要我有卡\n",
       "7    我的号码为啥暂暂停服务了稍等一下我帮您看了一下的话您之前的话有反映过这个问题的是吧然后的话我...\n",
       "8    哎你查一下我这个话费还有余额吗您这边还有8.95元怎么打不了怎么没有信号呢网络没有了呢呃信号...\n",
       "9    哎先生哦嗯我想问一下现在如果这个号码要补号码的话那个身份证复印件有没有有效的补卡补卡要原件的...\n",
       "Name: 转写文本, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预览预处理结果\n",
    "data_frame['转写文本'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "caf8c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = np.array(data_frame['转写文本'])\n",
    "choices = np.array(data_frame['服务请求'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "790333c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((526,), (100000, 1))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去重choices，并保存原choices对应去重后的位置\n",
    "unique_choices = np.unique(choices)\n",
    "labels = np.array([np.argwhere(unique_choices==v)[0] for v in choices])\n",
    "unique_choices.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "64a5c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 BertForMultipleChoice 模型\n",
    "class BertForMutipleChoiceModel(nn.Module):\n",
    "    def __init__(self, UseGPU, model_path, batch_size, max_length):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.model_path = model_path\n",
    "        self.max_length = max_length # 保存问题-答案最长编码\n",
    "        self.model_config = BertConfig.from_pretrained(self.model_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_path)\n",
    "        self.bertchoice = BertForMultipleChoice.from_pretrained(self.model_path, config=self.model_config)\n",
    "        self.try_gpu(UseGPU)\n",
    "        \n",
    "    def try_gpu(self, bUse):\n",
    "        if torch.cuda.device_count() and bUse == True >= 1:\n",
    "            self.device = 'cuda:0'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        self.bertchoice.to(self.device) # 迁移模型到device\n",
    "    \n",
    "    def format_choices(self, choices_text):\n",
    "        '''choices_text是已去重的np array(num_choices,)，且对应的答案label在外部维护。\n",
    "        对答案进行全局编码，方便后续使用，后续训练只需传入labels号'''\n",
    "        self.num_choices = choices_text.shape[0] # 答案的数量\n",
    "#         self.choices = np.repeat(np.reshape(choices_text, (1, -1)), self.batch_size, axis=0).tolist()\n",
    "        self.choices = choices_text.tolist()\n",
    "        \n",
    "        \n",
    "    def forward(self, prompt, labels):\n",
    "        '''prompt是问题文本 np array（batch_size*1）, label是对应这个问题的答案标号(batch_size,)'''\n",
    "        '''labels 为 tensor(batch_size, 1)'''\n",
    "        prompts =  np.repeat(prompt, self.num_choices, axis=1).tolist() # 重复问题准备拼接\n",
    "#         print('prompts', prompts)\n",
    "        # 由于 tokenizer 每次只能一个样本，需要通过循环处理\n",
    "        bFirst = True\n",
    "        save_encoding = None\n",
    "        for each_prompt in prompts:\n",
    "#             print('each_prompt', each_prompt)\n",
    "            encoding = self.tokenizer(each_prompt, self.choices, return_tensors='pt', padding='max_length', \n",
    "                                      truncation=True, max_length=self.max_length)\n",
    "            if bFirst:\n",
    "                bFirst = False\n",
    "                save_encoding = encoding\n",
    "                # 首次升维\n",
    "                for key in save_encoding:\n",
    "                    save_encoding[key] = save_encoding[key].unsqueeze(0)\n",
    "#                 print('save_encoding1', save_encoding)\n",
    "            else:\n",
    "                for key in save_encoding.keys():\n",
    "                    # 将 encodings 连接并输入模型\n",
    "#                     print('wait_to_concat', encoding)\n",
    "                    save_encoding[key] = torch.concat((save_encoding[key], encoding[key].unsqueeze(0)), dim=0)\n",
    "                \n",
    "#             print('encoding', encoding)\n",
    "#         print('save_encoding', save_encoding)\n",
    "\n",
    "        # 迁移到 device\n",
    "        labels = labels.to(self.device)\n",
    "        for key in save_encoding.keys(): # for 循环迭代器\n",
    "            save_encoding[key] = save_encoding[key].to(self.device)\n",
    "    \n",
    "        outputs = self.bertchoice(**{k: v for k, v in save_encoding.items()}, labels=labels) # 第 0 维为 batch_size\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e497c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2])\n",
    "a = a.to('cuda')\n",
    "a\n",
    "dic = {'s':a}\n",
    "for v in dic.values():\n",
    "    v = v.to('cpu')\n",
    "for v in dic.values():\n",
    "    print(v)\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "df3cdf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ./bert-base-chinese/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choices ['大聪明.' '大傻逼.']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17912\\3960025214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_choices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'choices'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17912\\459448734.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, prompt, labels)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m#         print('save_encoding', save_encoding)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbertchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msave_encoding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 第 0 维为 batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         )\n\u001b[0;32m   1671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1673\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m   1016\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2208\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "m = BertForMutipleChoiceModel(True, './bert-base-chinese/', 2, 100)\n",
    "prompt = np.array([[\"你是大聪明还是大傻逼\"],[\"你是学霸还是学渣\"]])\n",
    "# print(prompt.shape)\n",
    "choices = np.array([\"大聪明.\",\"大傻逼.\"])\n",
    "labels = torch.tensor([1, 0])\n",
    "m.format_choices(choices)\n",
    "print('choices', np.array(m.choices))\n",
    "print(m.forward(prompt,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Dataloader 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b85ec66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ./bert-base-chinese/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   100,   100,   117, 10315,  9342,  8180, 11667,  8217, 12244,\n",
      "          8315,  9738, 13288,   117, 11541,  8370,  8975,  8243,   143, 10637,\n",
      "           117,  8310, 11685, 11836,  8303,   163,  8727, 11809,  8303,   119,\n",
      "           102,   100,  8310,  9714, 11598,  8663,   143,  8330,  8197,  8256,\n",
      "           143,   153,  8833,  9568,   119,   102],\n",
      "        [  101,   100,   100,   117, 10315,  9342,  8180, 11667,  8217, 12244,\n",
      "          8315,  9738, 13288,   117, 11541,  8370,  8975,  8243,   143, 10637,\n",
      "           117,  8310, 11685, 11836,  8303,   163,  8727, 11809,  8303,   119,\n",
      "           102,   100,  8310,  9714, 11598,   165,  8963,  8268,  9245,  8635,\n",
      "          8217,  8174, 12126,  8168,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# 官方示例代码\n",
    "model_path = './bert-base-chinese/'\n",
    "# m = BertForMultipleChoice.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForMultipleChoice.from_pretrained(model_path)\n",
    "\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "choice0 = \"It is eaten with a fork and a knife.\"\n",
    "choice1 = \"It is eaten while held in the hand.\"\n",
    "labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1\n",
    "\n",
    "encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=\"pt\", padding=True)\n",
    "print(encoding)\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}, labels=labels)  # batch size is 1\n",
    "\n",
    "# the linear classifier still needs to be trained\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
