{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad14f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoConfig,AutoTokenizer,AutoModelForSequenceClassification,Trainer,TrainingArguments,DataCollatorWithPadding\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import re\n",
    "from pygtrans import Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 加载数据\n",
    "# excel_file = 'd:/基于深度学习的海量文本处理/第1阶段/10w.xlsx'\n",
    "# data_frame = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0311064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 随机抽样（预实验使用）\n",
    "# data_frame = data_frame.sample(n=30)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 停用词预处理\n",
    "# stop_words = ['您好','你好',':很高兴为您服务','请问有什么可以帮您','client','user',' ']\n",
    "# sep_words = ['。', '!', '?', ',']\n",
    "# def ProcessStopWords(text):\n",
    "#     for word in stop_words:\n",
    "#         text = text.replace(word,'')\n",
    "#     text = text.replace(':','。').replace('。','',1) # 删除第一个。\n",
    "#     # for word in sep_words:\n",
    "#     #     text = text.replace(word, '[SEP]')\n",
    "#     return text\n",
    "\n",
    "# data_frame['转写文本'] = data_frame['转写文本'].map(ProcessStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a7bd85-a003-4cb6-a9d0-394006be2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['转写文本'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标签预处理\n",
    "# regex = re.compile(r'^.*?>(.*?)>.*?$')\n",
    "# def ProcessLabels(text):\n",
    "#     text = text.replace('>>','>').replace('10019','')\n",
    "#     text = re.match(regex, text).groups()[0]\n",
    "#     return text\n",
    "\n",
    "# data_frame['服务请求'] = data_frame['服务请求'].map(ProcessLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa56f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览预处理结果\n",
    "# data_frame['转写文本'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb821bb-84ce-4d0c-a21e-3177611af8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练复盘并分析数据集后，考虑在前面的处理把 样本数<1000 的剔除，即剔除下列：\n",
    "# rm_labels = ['临时','其他','商机','资料信息','业务变更问题','投诉','故障']\n",
    "# for rm_label in rm_labels:\n",
    "#     data_frame.drop(data_frame[data_frame.服务请求 == rm_label].index, inplace=True)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcbb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 翻译转写文本\n",
    "# client = Translate(target='en')\n",
    "# temp = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a3ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试\n",
    "# pd.DataFrame(np.array([trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[0:2]).tolist())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a7223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_num = data_frame.shape[0]\n",
    "# batch = 100\n",
    "# epoch = int(total_num/batch)\n",
    "# print(f'共{epoch}部分')\n",
    "# for i in range(epoch):\n",
    "#     if not i == epoch - 1:\n",
    "#         print(f'{i}部分开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:(i+1)*batch]).tolist())]\n",
    "#     else:\n",
    "#         print('最后一轮开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:]).tolist())]\n",
    "    \n",
    "#     translated_res = np.array(translated_res)\n",
    "#     temp =  np.concatenate((temp, translated_res), axis=0)\n",
    "#     print(f'第{i}部分已完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f1ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated_res = temp\n",
    "# len(translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56adb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入翻译\n",
    "# # data_frame = data_frame.drop(columns=['translated_text'])\n",
    "# data_frame.insert(0, 'translated_text', value=translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4118e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 处理翻译出错的符号\n",
    "# def Finetune_translate(text):\n",
    "#     text = text.replace('&#39;','\\'')\n",
    "#     return text\n",
    "    \n",
    "# data_frame['translated_text'] = data_frame['translated_text'].map(Finetune_translate)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf8c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = np.array(data_frame['translated_text'])\n",
    "# choices = np.array(data_frame['服务请求'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184539ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['服务请求']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeb83d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取最大长度\n",
    "# data_frame.insert(data_frame.shape[1], 'text_len',None)\n",
    "# data_frame['text_len'] = data_frame['translated_text'].map(len)\n",
    "# max_length_index = data_frame['text_len'].argmax()\n",
    "# max_length = data_frame['text_len'].iloc[max_length_index]\n",
    "# max_length_index, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18291572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 观察文本长度分布（排除异常值）\n",
    "# data_frame.boxplot('text_len', grid=False, showfliers=False, color='Black')\n",
    "# plt.suptitle(\"\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.show()\n",
    "# # 由图可知，取512足够覆盖正常样本\n",
    "# max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "790333c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 去重choices，并保存原choices对应去重后的位置\n",
    "# unique_choices = np.unique(choices)\n",
    "# labels = np.array([np.argwhere(unique_choices==v)[0]  for v in choices])\n",
    "# unique_choices.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929ac497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入标签\n",
    "# data_frame.insert(0, 'label', value=labels)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f134167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取出特征与labels\n",
    "# df = data_frame[['label', 'translated_text', '服务请求']]\n",
    "# df[:10]\n",
    "# # 统计\n",
    "# df['label'].value_counts(ascending=True).plot.barh()\n",
    "# plt.title(\"Frequency of Classes\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45f67412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 手动处理样本非均衡情况\n",
    "# df4 = df[df['label'] == 4].sample(n=30000)\n",
    "# df2 = df[df['label'] == 2]\n",
    "# df1 = pd.DataFrame(np.repeat(df[df['label'] == 1].values, 2, axis=0), columns=df.columns)\n",
    "# df0 = pd.DataFrame(np.repeat(df[df['label'] == 0].values, 2, axis=0), columns=df.columns)\n",
    "# df3 = pd.DataFrame(np.repeat(df[df['label'] == 3].values, 2, axis=0), columns=df.columns)\n",
    "\n",
    "# df = pd.concat([df0, df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5a8d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 先排序 label，以便后续充分打乱\n",
    "# df = df.sort_values(by='服务请求')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61ae46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_excel_path = './PreProcess.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930a6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(save_excel_path) # 保存翻译结果，方便重复使用\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5beb5ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>服务请求</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, that is my account. The current network i...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How can I help you. Hey, let's see if my numbe...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Have the issues I reported not been resolved y...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>. Sorry, my number is blocked. Sir, please hol...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I would like to ask if there is anything I can...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Why. Um. I said, hey, my TV is out of order. I...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Can this card be used? Why can't it be activat...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>This is my card and I want to cancel it. Is it...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey that one. The broadband you have at your h...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Then help me restart it. Restart what? Sir. Ah...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    translated_text 服务请求\n",
       "0      0  Hey, that is my account. The current network i...   不满\n",
       "1      0  How can I help you. Hey, let's see if my numbe...   不满\n",
       "2      0  Have the issues I reported not been resolved y...   不满\n",
       "3      0  . Sorry, my number is blocked. Sir, please hol...   不满\n",
       "4      0  I would like to ask if there is anything I can...   不满\n",
       "5      0  Why. Um. I said, hey, my TV is out of order. I...   不满\n",
       "6      0  Can this card be used? Why can't it be activat...   不满\n",
       "7      0  This is my card and I want to cancel it. Is it...   不满\n",
       "8      0  Hey that one. The broadband you have at your h...   不满\n",
       "9      0  Then help me restart it. Restart what? Sir. Ah...   不满"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用于直接读取预处理完成的结果\n",
    "df = pd.read_excel(save_excel_path)\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.dropna(inplace=True) # drop 空行，防止 tokenize 失败\n",
    "\n",
    "# 预处理结果相关参数\n",
    "max_length = 512\n",
    "classic_num = 5\n",
    "\n",
    "# 预览\n",
    "print(df.shape[0])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f337b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 79460\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 19866\n",
       "     })\n",
       " }),\n",
       " {'label': 4,\n",
       "  'text': \"Hey, my monthly rent is 48, why is it now changed to 663? What's going on? let me see. A set meal. There is no change and it is still the 48 package. I just sent a text message and he said that my monthly package is 63. What's going on? Oh no, that was last month when you ordered a data package and he included the cost of that data package. Oh, okay, okay, it’s still 48, right? Is this the case? There is nothing unusual about your money, or the 48 yuan has not changed in a month. Thank you very much. Um, I would like to ask, sir, if there is any other business that I would like to consult. Ah, no, no more. Okay, if there is no information, I won’t bother you. Thank you for your call later. If you receive a satisfaction survey text message, please help me reply with the number 1. Thank you and bye. well\",\n",
       "  '__index_level_0__': 89732},\n",
       " {'label': 1,\n",
       "  'text': \"Well, why do I have no traffic? Does the cap need to be lifted? I don't know. Please look for it for me. Uh, if the traffic is capped, we have already helped you, uh, we have helped you to cancel the shutdown and restart, and you can use it in about 3 to 5 minutes. It's been lifted, right? After the subsequent usage of the data exceeds, you will be charged according to your package rate of 1 yuan per GB of daily rental treasure. Is there anything I can help you with? Shut down. Shut down and restart your computer for about 3 to 5 minutes and try again. Okay, okay, thank you. Well, if you're welcome, I won't disturb you for now. OK, I won't bother you anymore. Ah, thank you for your call. I will receive a satisfaction survey text message later. Please reply. Bye-Bye\",\n",
       "  '__index_level_0__': 12762})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建数据集\n",
    "ds = DatasetDict({'train': Dataset.from_pandas(df)})\n",
    "# ds['train'] = ds['train'].rename_column('转写文本','text')\n",
    "ds = ds.remove_columns(['服务请求'])\n",
    "\n",
    "ds['train'] = ds['train'].rename_columns({'translated_text':'text'})\n",
    "ds = ds['train'].train_test_split(0.2, shuffle=True) # 按 8:2 分割数据集\n",
    "ds, ds['train'][0], ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f99bd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 79460/79460 [00:23<00:00, 3437.97 examples/s]\n",
      "Map: 100%|██████████| 19866/19866 [00:05<00:00, 3541.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 667 ms, total: 1min 34s\n",
      "Wall time: 28.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = './bert-base-cased/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length)\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6877ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # 允许不同长度tensor的存在\n",
    "model_config = AutoConfig.from_pretrained(model_path)\n",
    "model_config.num_labels = classic_num\n",
    "model = AutoModelForSequenceClassification.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa78d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': \"Hey, my monthly rent is 48, why is it now changed to 663? What's going on? let me see. A set meal. There is no change and it is still the 48 package. I just sent a text message and he said that my monthly package is 63. What's going on? Oh no, that was last month when you ordered a data package and he included the cost of that data package. Oh, okay, okay, it’s still 48, right? Is this the case? There is nothing unusual about your money, or the 48 yuan has not changed in a month. Thank you very much. Um, I would like to ask, sir, if there is any other business that I would like to consult. Ah, no, no more. Okay, if there is no information, I won’t bother you. Thank you for your call later. If you receive a satisfaction survey text message, please help me reply with the number 1. Thank you and bye. well\",\n",
       " '__index_level_0__': 89732,\n",
       " 'input_ids': [101,\n",
       "  4403,\n",
       "  117,\n",
       "  1139,\n",
       "  7868,\n",
       "  9795,\n",
       "  1110,\n",
       "  3615,\n",
       "  117,\n",
       "  1725,\n",
       "  1110,\n",
       "  1122,\n",
       "  1208,\n",
       "  2014,\n",
       "  1106,\n",
       "  5046,\n",
       "  1495,\n",
       "  136,\n",
       "  1327,\n",
       "  112,\n",
       "  188,\n",
       "  1280,\n",
       "  1113,\n",
       "  136,\n",
       "  1519,\n",
       "  1143,\n",
       "  1267,\n",
       "  119,\n",
       "  138,\n",
       "  1383,\n",
       "  7696,\n",
       "  119,\n",
       "  1247,\n",
       "  1110,\n",
       "  1185,\n",
       "  1849,\n",
       "  1105,\n",
       "  1122,\n",
       "  1110,\n",
       "  1253,\n",
       "  1103,\n",
       "  3615,\n",
       "  7305,\n",
       "  119,\n",
       "  146,\n",
       "  1198,\n",
       "  1850,\n",
       "  170,\n",
       "  3087,\n",
       "  3802,\n",
       "  1105,\n",
       "  1119,\n",
       "  1163,\n",
       "  1115,\n",
       "  1139,\n",
       "  7868,\n",
       "  7305,\n",
       "  1110,\n",
       "  5519,\n",
       "  119,\n",
       "  1327,\n",
       "  112,\n",
       "  188,\n",
       "  1280,\n",
       "  1113,\n",
       "  136,\n",
       "  2048,\n",
       "  1185,\n",
       "  117,\n",
       "  1115,\n",
       "  1108,\n",
       "  1314,\n",
       "  2370,\n",
       "  1165,\n",
       "  1128,\n",
       "  2802,\n",
       "  170,\n",
       "  2233,\n",
       "  7305,\n",
       "  1105,\n",
       "  1119,\n",
       "  1529,\n",
       "  1103,\n",
       "  2616,\n",
       "  1104,\n",
       "  1115,\n",
       "  2233,\n",
       "  7305,\n",
       "  119,\n",
       "  2048,\n",
       "  117,\n",
       "  3008,\n",
       "  117,\n",
       "  3008,\n",
       "  117,\n",
       "  1122,\n",
       "  787,\n",
       "  188,\n",
       "  1253,\n",
       "  3615,\n",
       "  117,\n",
       "  1268,\n",
       "  136,\n",
       "  2181,\n",
       "  1142,\n",
       "  1103,\n",
       "  1692,\n",
       "  136,\n",
       "  1247,\n",
       "  1110,\n",
       "  1720,\n",
       "  5283,\n",
       "  1164,\n",
       "  1240,\n",
       "  1948,\n",
       "  117,\n",
       "  1137,\n",
       "  1103,\n",
       "  3615,\n",
       "  194,\n",
       "  8734,\n",
       "  1144,\n",
       "  1136,\n",
       "  2014,\n",
       "  1107,\n",
       "  170,\n",
       "  2370,\n",
       "  119,\n",
       "  4514,\n",
       "  1128,\n",
       "  1304,\n",
       "  1277,\n",
       "  119,\n",
       "  12189,\n",
       "  117,\n",
       "  146,\n",
       "  1156,\n",
       "  1176,\n",
       "  1106,\n",
       "  2367,\n",
       "  117,\n",
       "  6442,\n",
       "  117,\n",
       "  1191,\n",
       "  1175,\n",
       "  1110,\n",
       "  1251,\n",
       "  1168,\n",
       "  1671,\n",
       "  1115,\n",
       "  146,\n",
       "  1156,\n",
       "  1176,\n",
       "  1106,\n",
       "  27231,\n",
       "  119,\n",
       "  7066,\n",
       "  117,\n",
       "  1185,\n",
       "  117,\n",
       "  1185,\n",
       "  1167,\n",
       "  119,\n",
       "  3956,\n",
       "  117,\n",
       "  1191,\n",
       "  1175,\n",
       "  1110,\n",
       "  1185,\n",
       "  1869,\n",
       "  117,\n",
       "  146,\n",
       "  1281,\n",
       "  787,\n",
       "  189,\n",
       "  8255,\n",
       "  1128,\n",
       "  119,\n",
       "  4514,\n",
       "  1128,\n",
       "  1111,\n",
       "  1240,\n",
       "  1840,\n",
       "  1224,\n",
       "  119,\n",
       "  1409,\n",
       "  1128,\n",
       "  3531,\n",
       "  170,\n",
       "  10241,\n",
       "  5980,\n",
       "  3087,\n",
       "  3802,\n",
       "  117,\n",
       "  4268,\n",
       "  1494,\n",
       "  1143,\n",
       "  7163,\n",
       "  1114,\n",
       "  1103,\n",
       "  1295,\n",
       "  122,\n",
       "  119,\n",
       "  4514,\n",
       "  1128,\n",
       "  1105,\n",
       "  11901,\n",
       "  119,\n",
       "  1218,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a78c0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估\n",
    "accuracy = evaluate.load('./evaluate/metrics/accuracy/accuracy.py')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2d659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 训练阶段\n",
    "training_args = TrainingArguments('./output',evaluation_strategy='epoch',save_strategy='epoch', learning_rate=5e-7, \n",
    "                                    load_best_model_at_end=True, num_train_epochs=3)\n",
    "trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78796024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='29799' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   10/29799 02:04 < 128:46:39, 0.06 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:2\u001b[0m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/transformers/trainer.py:1835\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1835\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1838\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1841\u001b[0m ):\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/transformers/trainer.py:2690\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2688\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/accelerate/accelerator.py:1985\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 训练\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "946d210a-5dee-4ce8-93c3-5f0b5ef04c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 训练阶段\n",
    "ds = ds.shuffle(88) # 再次打乱数据集\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-8)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "training_args = TrainingArguments('./output',evaluation_strategy='epoch',save_strategy='epoch',\n",
    "                                load_best_model_at_end=True, num_train_epochs=5)\n",
    "trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, \n",
    "                  compute_metrics=compute_metrics, optimizers=(optimizer, lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f643e-7d67-485f-998f-4c00291efdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='49665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   42/49665 00:05 < 1:56:48, 7.08 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# 精准训练\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
